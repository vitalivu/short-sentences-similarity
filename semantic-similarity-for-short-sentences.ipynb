{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "semantic-similarity-for-short-sentences.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPkAHfmowPYK"
      },
      "source": [
        "## SentenceBERT\n",
        "\n",
        "For original paper, see [arxiv.org](https://arxiv.org/abs/1908.10084)\n",
        "\n",
        "To work with this notebook, install with `pip`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VxEjg6aTwPYb"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vSF6btPwPYc"
      },
      "source": [
        "## Data\n",
        "This note nook using data from [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsHdAWanwPYd"
      },
      "source": [
        "### Running in Kaggle\n",
        "\n",
        "List the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "66lTO9cMwPYe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vIt64cljwPYe"
      },
      "source": [
        "df = pd.read_csv('../input/train.csv.zip', compression='zip', sep=',')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhOKQbNewqcK"
      },
      "source": [
        "### Running in Colab\n",
        "\n",
        "In Colab, data stores in Google Drive. You have to upload your dataset manually to your google drive, then connect from this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OTbMQJCFwPYc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOhxf_oXwPYc"
      },
      "source": [
        "List the files, eg `data/quora/input`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fZ9xrwDqwPYd"
      },
      "source": [
        "%ls /gdrive/MyDrive/Colab\\ Notebooks/data/quora/input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tTYQu01RwPYd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/gdrive/MyDrive/Colab Notebooks/data'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mXQ9D7DHwPYd"
      },
      "source": [
        "df = pd.read_csv('/gdrive/MyDrive/Colab Notebooks/data/quora/input/train.csv.zip', compression='zip', sep=',')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sPAQe67zwPYe"
      },
      "source": [
        "### Locally with Ubuntu\n",
        "\n",
        "`TBD`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7pJsGXDbwPYe"
      },
      "source": [
        "### Example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sKb_dj2YwPYf"
      },
      "source": [
        "question1 = df['question1'].unique()\n",
        "question1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjs1IN7CwPYf"
      },
      "source": [
        "### Clean data\n",
        "\n",
        "- Lowercase original sentences\n",
        "- Remove some nonsense words, non-ASCII character\n",
        "- Replace with common phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3-6Yr-D-wPYf"
      },
      "source": [
        "stopwords = set(['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'which', 'while', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'])\n",
        "\n",
        "\n",
        "def cleantext(sent):\n",
        "    # Removing non ASCII chars\n",
        "    sent = str(sent).replace(r'[^\\x00-\\x7f]',r' ')\n",
        "\n",
        "    # Replace some common paraphrases\n",
        "    sent_norm = sent.lower()\\\n",
        "        .replace(\"how do you\", \"how do i\")\\\n",
        "        .replace(\"how do we\", \"how do i\")\\\n",
        "        .replace(\"how can we\", \"how can i\")\\\n",
        "        .replace(\"how can you\", \"how can i\")\\\n",
        "        .replace(\"how can i\", \"how do i\")\\\n",
        "        .replace(\"really true\", \"true\")\\\n",
        "        .replace(\"what are the importance\", \"what is the importance\")\\\n",
        "        .replace(\"what was\", \"what is\")\\\n",
        "        .replace(\"so many\", \"many\")\\\n",
        "        .replace(\"would it take\", \"will it take\")\n",
        "\n",
        "    # Remove any punctuation characters\n",
        "    for c in [\",\", \"!\", \".\", \"?\", \"'\", '\"', \":\", \";\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\"]:\n",
        "        sent_norm = sent_norm.replace(c, \" \")\n",
        "\n",
        "    # Remove stop words\n",
        "    tokens = sent_norm.split()\n",
        "    tokens = [token for token in tokens if token not in stopwords]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "cleantext('What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTXoGTOOwPYg"
      },
      "source": [
        "replace data with cleaned data: replace `question` with `cleantext(question)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I0Vr2TcMwPYg"
      },
      "source": [
        "question1 = df['question1'].unique()\n",
        "question1 = np.array(list(map(cleantext, question1)))\n",
        "question1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ue0FW2mOwPYh"
      },
      "source": [
        "question2 = df['question2'].unique()\n",
        "question2 = np.array(list(map(cleantext, question2)))\n",
        "question2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6BECyamwPYh"
      },
      "source": [
        "## Models\n",
        "\n",
        "### Create the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LhAjnFwfwPYh"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from time import perf_counter\n",
        "\n",
        "\n",
        "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
        "\n",
        "startTime = perf_counter()\n",
        "embeddings1 = model.encode(question1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(question2, convert_to_tensor=True)\n",
        "endTime = perf_counter()\n",
        "print(\"Computed sentence embeddings in {:.4f} seconds\".format(endTime - startTime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yra8LkrKwPYi"
      },
      "source": [
        "## Experiments\n",
        "Create a simple query and search for top 5 results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h3oqjPBwdnR"
      },
      "source": [
        "### Bi-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LPIypuEIwPYi"
      },
      "source": [
        "from time import perf_counter\n",
        "import torch\n",
        "\n",
        "queries = ['What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?'] # example from question1\n",
        "\n",
        "top_5 = min(5, len(embeddings2))\n",
        "\n",
        "time_t1 = perf_counter()\n",
        "for query in queries:\n",
        "    query_embedding = model.encode(cleantext(query), convert_to_tensor=True)\n",
        "    cos_scores = util.pytorch_cos_sim(query_embedding, embeddings2)[0]\n",
        "    top_results = torch.topk(cos_scores, k=top_5)\n",
        "    print(\"### Query:\", query)\n",
        "    print(\"Top 5 most similar queries:\")\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        print(\"({:.4f})\".format(score), question2[idx])\n",
        "\n",
        "time_t2 = perf_counter()\n",
        "print(\"Compute consine-similarity in\",\"{:.4f}\".format(time_t2 - time_t1),\"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmSnEdM6wPYi"
      },
      "source": [
        "### Cross-Encoder\n",
        "\n",
        "Cannot run cross-encoder for the large dataset:\n",
        "- memory limitation,\n",
        "- computation ability and time-consuming\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkRqX2Iewhkg"
      },
      "source": [
        "### Combination\n",
        "Using the top 100 in Bi-encoder to evaluate with Cross-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8qzBIVyvwPYj"
      },
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "from time import perf_counter\n",
        "import torch\n",
        "\n",
        "query = 'What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?' # example from question1\n",
        "\n",
        "top_100 = min(100, len(embeddings2))\n",
        "\n",
        "time_t1 = perf_counter()\n",
        "query_embedding = model.encode(cleantext(query), convert_to_tensor=True)\n",
        "cos_scores = util.pytorch_cos_sim(query_embedding, embeddings2)[0]\n",
        "top_results = torch.topk(cos_scores, k=top_100) # select top 100\n",
        "\n",
        "top_sentences = [ question2[idx] for idx in zip(top_results[1])] # extract top 100 sentences\n",
        "\n",
        "time_t2 = perf_counter()\n",
        "sentence_combinations = [[query, sentence] for sentence in top_sentences]\n",
        "\n",
        "cross_encoder = CrossEncoder('cross-encoder/stsb-distilroberta-base')\n",
        "similarity_scores = cross_encoder.predict(sentence_combinations)\n",
        "sim_scores = reversed(np.argsort(similarity_scores))\n",
        "\n",
        "print(\"### Query:\", query)\n",
        "print(\"Top 5 most similar queries:\")\n",
        "for idx in [sim_score for _,sim_score in zip(range(5), sim_scores)]:\n",
        "    print(\"({:.4f}) {}\".format(similarity_scores[idx], top_sentences[idx]))\n",
        "\n",
        "time_t3 = perf_counter()\n",
        "print(\"Compute bi-encoder in\",\"{:.4f}\".format(time_t2 - time_t1),\"seconds\")\n",
        "print(\"Compute cross-encoder from top 100 in\",\"{:.4f}\".format(time_t3 - time_t2),\"seconds\")\n",
        "print(\"Total time: \", \"{:.4f}\".format(time_t3 - time_t1), \"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J9DfUWZwPYj"
      },
      "source": [
        "## Note and TODO\n",
        "Cannot apply to caculate for all sentences in both sets (memory not enough for 230TB =)) so:\n",
        "- we can apply one by one\n",
        "- a signmoi function: threshold for similarity scores to mark a question is similar or not\n",
        "    - linear regression to select the proper threshold\n",
        "- calculate the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64BPIBSmwPYj"
      },
      "source": [
        "## Export and import the model\n",
        "\n",
        "Export model to file. File can be used to restore model later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ue5IKBs9wPYk"
      },
      "source": [
        "import pickle\n",
        "\n",
        "#Store sentences & embeddings on disc\n",
        "with open('question1.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'sentences': question1, 'embeddings': embeddings1}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('question2.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'sentences': question2, 'embeddings': embeddings2}, fOut, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcYRn3zAwPYk"
      },
      "source": [
        "Import model from file. In our case, kaggle generates model, then we use the pre-trained model to create the search engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WZuZlDabwPYk"
      },
      "source": [
        "#Load sentences & embeddings from disc\n",
        "with open('question1.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    question1 = stored_data['sentences']\n",
        "    embeddings1 = stored_data['embeddings']\n",
        "with open('question2.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    question2 = stored_data['sentences']\n",
        "    embeddings2 = stored_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}